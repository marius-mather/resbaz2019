# Compute Day Details

Friday 13th September

<table class="csv-table">
<thead>
<tr>
<th>Time</th>
<th>Stream 1</th>
<th>Stream 2a</th>
<th>Stream 2b</th>
<th>Stream 3</th>
</tr>
</thead>
<tbody>
<tr>
<td>09:30-11:30</td>
<td>NCI: Intro</td>
<td>GCP Hands on</td>
<td>MS Azure Hands on</td>
<td>Intro to Linux and HPC</td>
</tr>
<tr>
<td>11:30-12:00</td>
<td>NCI: NCMAS</td>
<td>(cont’d)</td>
<td>(cont’d)</td>
<td>(cont’d)</td>
</tr>
<tr>
<td>12:00-12:30</td>
<td>NCI: Q&A</td>
<td>(cont’d)</td>
<td>(cont’d)</td>
<td>(cont’d)</td>
</tr>
<tr>
<td>13:15-14:15</td>
<td>Pawsey</td>
<td>AWS/Ronin Hands on</td>
<td></td>
<td>Mathworks 1</td>
</tr>
<tr>
<td>14:15-15:15</td>
<td>(cont’d)</td>
<td>(cont’d)</td>
<td></td>
<td>Mathworks 2</td>
</tr>
<tr>
<td>15:15-16:15</td>
<td>UNSW Katana</td>
<td>(cont’d)</td>
<td></td>
<td>Mathworks 3</td>
</tr>
</tbody>
</table>


## NCI (Stream 1)

Presenter: Rika Kobayashi

Rika Kobayashi is an Academic Consultant specialising in computational chemistry as
part of the user support team at NCI. Her responsibilities are to install, maintain and
provide expert support for application software over all disciplines, especially in
technical matters regarding high-performance computing.
Her background is in theoretical and computational chemistry in which she obtained
her PhD at the University of Cambridge under the supervision of Nicholas Handy.
She specialises in method development and implementation and has
provided code for various software packages: coupled cluster
and response properties in DALTON, the original CCSD(T) module in NWChem
and the CAM-B3LYP density functional in Gaussian. In her spare time she carries out
research and is currently working on Machine Learning in chemistry and material science

### Introduction to NCI and Gadi, NCI's new high-performance machine

09:30-11:30

NCI Australia is funded under the Australian Government’s NCRIS initiative to provide world-class integrated high-performance computing services to Australian researchers.  Based at The Australian National University, NCI is home to the Southern Hemisphere’s fastest supercomputer, a high-performance research cloud and Australia’s largest research data repository.
Gadi, the next-generation high-performance machine for NCI, is due to come online later this year. 

This session will give a brief overview of the NCI systems and services, particularly in the context of what to expect on the new machine:
- user and project management
- software environment
- filesystems
- batch queue system

### Introduction to the National Computational Merit Allocation Scheme (NCMAS)

11:30-12:00

The National Computational Merit Allocation Scheme provides access to resources at the major national HPC facilities for researchers at Australian universities and publicly funded research agencies. The call for applications for 2020 is now open and allocations will be determined through a highly competitive merit-based peer review process. Applications will be judged on both research and computational merit. 

This short information session will guide existing and potential future project leaders through the application process and strategies for success.

### Questions and Answers

12:00-12:30

## Pawsey (Stream 1)

13:15 - 15:00

*“Is your science causing your laptop to melt? Identifying when to scale your research.”*

How do you know when your dataset becomes “big data”? How do you know when your laptop can no longer do what you need it to do for your research? When is it best to use Cloud resources? When is it best to use super compute resources? When do I need both? 
 
The answers to these questions are project-dependent, and each project is different… but there are guidelines and best practices to help you decide.
 
During this workshop, we seek to answer these and associated questions. We use real stories from individuals who have had to navigate these same questions. Pawsey Supercomputing Centre staff will be on hand to facilitate discussion and provide insight, based on years of experience working with early, mid and late career researchers.

## UNSW Katana (Stream 1)

15:15-16:15

An introduction to <a href="https://research.unsw.edu.au/katana">UNSW's Katana</a> (a service for UNSW researchers).

What do you do when your computing needs can no longer be met by your desktop or laptop? The obvious solution is to purchase a workstation or server, perhaps with some specialized hardware like GPUs. But this leads to the question of where it is going to be located and who is going to support it.

Katana is a modular computational cluster where the core infrastructure such as networking, storage and several shared nodes are already paid for. Research groups who wish to use the system more extensively than a base level provided to everyone at UNSW, or those who wish to purchase specialized hardware can buy one or more compute nodes and let ResTech do the rest. This co-investment model has allowed Katana to grow from an initial 5 compute nodes to the current size of over 100 nodes making it the primary on campus resource for research computing.


## Google Cloud Platform (GCP) (Stream 2a)

09:30-12:30

In this hands-on workshop, we provide an introduction to [Google Cloud](https://cloud.google.com/) and showcase the services that researchers can leverage for compute, storage and machine learning applications. The session assumes no previous knowledge of Google Cloud and is suitable for both beginner and intermediate users of Cloud Computing services.

During this session we will be focused on the following activities:
1. Provisioning a Virtual Machine by using [Compute Engine](https://cloud.google.com/compute/) on Google Cloud
2. Methods for containerising toolsets and executing workloads on Google Cloud
3. Introduction to the Pipelines API and [Google Genomics](https://cloud.google.com/genomics/)

## MS Azure Hands on workshop  (Stream 2b)

09:30-12:30

1. Introduce the fundamentals of Azure services and data movement.
2. Show how Azure tools can be used to provision high-performance computing services, including those relevant to Artificial Intelligence.
3. Demonstrate how Azure could be used to easily deploy parallel workloads at scale with minimal development.
4. Showcase how Azure is being leveraged by researchers to accelerate research output.
5. Discuss opportunities to leverage the Microsoft team for your computing needs.

### AWS/Ronin  (Stream 2a)

13:15 - 16:15

AWS

- Intro to AWS & Research on AWS (How, why)
- Best Practice & Customer Stories & Getting Started.

Ronin

- Build and launch an R-studio environment in under 2 minutes.
- Build and launch an auto scaling cluster in under 5 minutes.
- Simple and Safe object storage.
- Managing your spend in the cloud, per project and per university.

## Intro to Linux and HPC (Stream 3)

09:30-12:30

A free hands-on tutorial for beginners to Linux and/or High Performance Computing.  No prior Linux or HPC knowledge or experience required!

Topics covered will include:

- How to connect to a HPC system using Secure Shell
- Using the BASH shell: commands, directories
- Transferring files to and from HPC systems
- Editing files using Nano or another text editor
- Simple scripting: creating shell script files, looping, variables
- Submitting and deleting jobs
- Checking on job status
- Discovering job queues and resources

You may wish to look through the <a href="https://www.zap.org.au/~john/links/intro-to-linux-and-hpc.pdf">course notes before attending</a>; this is entirely optional.  Additional verbal material will be presented during the tutorial.


## Managing and pre-processing messy data with MATLAB (Stream 3)

13:15 - 14:15

This session presents a variety of new MATLAB® features for accessing, organizing, and analyzing data. A special focus on:

1. the MATLAB datastore framework for working with large collections of files and
2. MATLAB datatypes for organizing and pre-processing sensor data.

See how these tools enable technical teams to grow from ad-hoc data analysis to building centralized tools for organization-wide use, laying a foundation for delivering production apps and analytics.
 
## Deep Learning and Reinforcement Learning Workflows in AI (Stream 3)

14:15 - 15:15

AI techniques are underpinning a dramatic change in research and analysis. Two new workflows, Deep Learning and Reinforcement Learning, are transforming industries and improving applications such as diagnosing medical conditions, driving autonomous vehicles, and controlling robots.. This session will cover:

- Machine Learning with code and APPS. Extending to automatic conversion of the Machine Learning designs to  (C/C++)
- Deep Learning via CNNs with code and APPS, extending to automatic conversion to CUDA for high speed execution on GPU's
- Importing Deep Learning models from other languages/networks via ONNX  into MATLAB.
- Reinforcement learning in MATLAB
- Application examples  including: Cancer diagnosis & Semantic segmentation for computer vision systems on autonomous vehicles
 
## Speeding up MATLAB Applications (Stream 3)

15:15 - 16:15

Learn strategies and techniques for speeding up your MATLAB applications. Included are tips on how to optimize the performance of the MATLAB code itself and how to use the MATLAB family of products to take advantage of advances in hardware, such as multicore desktops, computer clusters, and public clouds.
